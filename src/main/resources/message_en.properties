app-log-continue=Input "q" or "Q" to quit, other key to view log of other Spark Application
app-index-select=Please input Spark Application id or number in the list above(input 'q' to terminate program): 
app-not-found=Cannot find any Spark Application with key word {0} contained
app-not-running=Application {0} is not running but {1} , to see executor logs is meaningless
argument-compare-mapping=source: destination
argument-export=exportType
argument-expression=variable=expression
argument-parameter=variable=value
argument-script=scriptName
closed=Connection to {0} is closed, please reconnect it manually
closing=Closing: {0}: {1}
column-address=address
column-elapsed-time=elapsed time
column-executor-address=executor address
column-finish-time=finish time
column-is-active=is active
column-launch-time=launch time
column-log-address=log address
column-memory=memory
column-name=name
column-order-number=number
column-status=status
command-not-supported=Command {0} is not supported
connecting=Connecting to {0} ...
description-alter=Alter external Hive Over HBase table, need following parameters provided: {0}
description-alter-add=Sub-option of {0}, add column to external Hive Over HBase table.
description-alter-drop=Sub-option of {0}, drop column from external Hive Over HBase table.
description-compare=Compare table schema between MySQL and Hive, following parameters need to be provided when sub-option {0} and {1} is not provided: {2}.
description-compare-database=Sub-option of {0}, it indicates that program read table information from database to compare differences of table's schema, following parameters need to be provided: {1}
description-compare-file=Sub-option of {0}, it indicates that program read table information from file to compare differences of table's schema, need option {1} or {2} provided.
description-compare-file-header=Sub-option of {0}, it indicates that the file has header when read table information from configuration file to compare differences of table's schema, following parameters need to be provided: {1}.
description-compare-file-index=Sub-option of {0}, it indicates that the columns has index when read table information from configuration file to compare differences of table's schema, following parameters need to be provided: {1}.
description-compare-mapping=Sub-option of {0}, ignored type mapping, such as varchar mapping to string is necessary to ignored.
description-expression=dynamically evaluate expression and argue to a variable
description-generator=HBase Catalog generator.\nFollowing parameters need to be provided: {0}(HBase columns separated by comma), hbase.column.some_column which some_column properties means column family name, column name and data type separated by colon.
description-help=list usage of this program
description-log=Interactively view Driver log or Executor log of Spark Appcation, following parameters need to be provided: {0}
description-parameter=parameters
description-query=Interactively query tool
description-script=Analyse and execute sql script, support sql query to hbase
description-universal-email=Universal sub-option, send an e-mail, following parameters need to be provided: {0}
description-universal-export=Universal sub-option, export type, can be one of mysql, redis, ssv, none, and default is none.\nFor mysql, following parameters need to be provided: {0}.\nFor redis, following parameters need to be provided: {1}.\nFor ssv, following parameters need to be provided: {2}.
executor-index-select=Please input executor number and length(default is -4096) of log (input 'q' to terminate program, input 's' to save file, input separated by space): 
executor-log-continue=Input "q" or "Q" to quit, other symbol to see logs of other executor: 
executor-not-found=Cannot find any executors now, input Y/y to try a minute later, other symbol to quit: 
executor-not-in-list=Inputted number of executor is not in the list,
executor-or-driver-log-following={1} log of application {0} is following: \n{2}
field-not-found-in-json=Cannot find field {0} from json\n{1}
continue-on-input=Input "q" or "Q" to quit, other symbol to continue:
help-alter=Alter column of Hive Over HBase external table
help-close=Close current jdbc connection
help-closeAll=Close all open jdbc connections
help-columns=List all columns information of specified table, equals to desc <table name>
help-compare=Compare table schema between MySQL and Hive
help-connect=Open or establish connection to specified jdbc url
help-execute=Analyse and execute sql script, support sql query to hbase
help-get=Acquire value of specified configuration
help-generate=generate HBase Catalog
help-go=Switch to specified connection
help-help=Acquire help document
help-history=Acquire history input
help-list=List all open jdbc connections
help-log=View Driver log or Executor log of Spark Appcation
help-null2Empty=Whether output null as empty string, equals to !set print.null2empty=true or !set print.null2empty true
help-outputFormat=Set output format of query or execute result, equals to !set print.format=<format> or !set print.format <format>, supported values are: \n\
  csv: comma separated values\n\
  default: 2-dimensional table with border\n\
  dsv:  pipe operator | separated values\n\
  json: output with json format, json style is controlled by configuration print.json.pretty, false is compressed style, true is formatted style\n\
  tsv: tab separated values\n\
  vertical: output with key-value format one row by one row\n\
  xml_attributes: output with xml node attributes\n\
  xml_elements: ouput with xml node elements
help-quit=Terminate the program after close all open connections
help-reconnect=Reconnect current closed connection
help-register=Analyse HBase Catalog and register as memory table
help-set=Set value of specified configuration with immediate effect
help-showFunctions=List all functions supported by current connection
help-syntax=Usage: {0}
help-tables=List all tables or tables match specified pattern in current database
invalid-connection=Invalid connection: {0}
multiple-matches=Ambiguous command: {0}
no-current-connection=No current connection
no-such-method=No method "{0}" found in "{1}"
parameter-format-limitation={0} must be {1},
parameter-value-limitation2={0} only can be {1} or {2}
parameter-input=please input value of {0}(press RETURN to ignore):
can-not-abort=Operation can not be aborted, press Ctrl+C again to exit
query-aborted=Query aborted
reconnecting=Reconnecting to {0} ...
row-selected=0#No rows selected|1#{0} row selected|1<{0} rows selected
row-displayed=0#No rows displayed|1#{0} row displayed|1<{0} rows displayed
row-effected={0} rows effected
time-elapsed=({0} seconds elapsed)
unknown-command=Unknown command: {0}
unknown-filter=Unknown filter: {0}
unknown-format=Unknown output format "{0}", possible values: {1}
usage-footer=Notice: when multi level 1 option is provided, priority order is 
usage-header=Use: add or delete column in external Hive table, compare schema differences between MySQL source table and Hive destination table, execute SQL script, generate HBase Catalog, interactively query
#HBase filter usage and function
filter-ColumnCountGetFilter=Usage: ColumnCountGetFilter(limit), returns first limit columns each row while columns number isn't less than limit
filter-ColumnPaginationFilter=Usage: ColumnCountGetFilter(limit offset), return limit columns after offset columns each row while columns number isn't less than limit plus offset
filter-ColumnPrefixFilter=Usage: ColumnPrefixFilter(prefix)
filter-ColumnRangeFilter=Usage: ColumnRangeFilter(minColumn,minColumnInclusive,maxColumn,maxColumnInclusive)
filter-DependentColumnFilter=Usage: DependentColumnFilter(family,qualifier,dropDependentColumn,valueCompareOp,valueComparator)
filter-FamilyFilter=Usage: FamilyFilter(familyCompareOp,familyComparator)
filter-FirstKeyOnlyFilter=Usage: FirstKeyOnlyFilter()
filter-InclusiveStopFilter=Usage: InclusiveStopFilter(stopRowKey)
filter-KeyOnlyFilter=Usage: KeyOnlyFilter()
filter-MultipleColumnPrefixFilter=Usage: MultipleColumnPrefixFilter(prefix...)
filter-PageFilter=Usage: PageFilter(pageSize)
filter-PrefixFilter=Usage: PrefixFilter(prefix)
filter-QualifierFilter=Usage: QualifierFilter(qualifierCompareOp,qualifierComparator)
filter-RowFilter=Usage: RowFilter(rowCompareOp,rowComparator)
filter-SingleColumnValueExcludeFilter=Usage: SingleColumnValueExcludeFilter(family,qualifier,compareOp,value)
filter-SingleColumnValueFilter=Usage: SingleColumnValueFilter(family,qualifier,compareOp,value)
filter-TimestampsFilter=Usage: TimestampsFilter(timestamp...)
filter-ValueFilter=Usage: ValueFilter(valueCompareOp,valueComparator)
#HBase commands usage
usage-clone=Usage: clone <snapshot> <table>
usage-count=Usage: count <table>
usage-create=Usage: create <table> <family1>[ family2][ family3]...
usage-create_namespace=Usage: create <namespace>
usage-delete=Usage: delete <table> <row_key>[ <family> <qualifier> [timestamp]]
usage-delete_snapshot=Usage: delete_snapshot <snapshot>
usage-disable=Usage: disable <table>
usage-disable_and_drop=Usage: disable_and_drop <table>
usage-drop=Usage: drop <table>
usage-enable=Usage: enable <table>
usage-get=Usage：get <table> <row key>
usage-list=Usage: list [regex pattern]
usage-list_filters=Usage: list_filters
usage-list_namespace=Usage: list_namespace
usage-list_namespace_tables=Usage: list_namespace_tables <namespace> [regex pattern]
usage-list_snapshots=Usage: list_snapshots [regex pattern]
usage-put=Usage: put <table> <row key> <family> <qualifier> <value>
usage-scan=Usage: scan <table>[ LIMIT=>? FILTER=>? PAGE=>? FILTER=>? ...]
usage-search=Usage：search <table>
press-again=Press Ctrl-C again to force exit
usage-snapshot=Usage: snapshot <table> <snapshot>
#Hive/Common commands usage
usage-connect=Usage: !connect <url> [username] [password] [driver]
usage-!get=Usage: !get <key>
usage-go=Usage: !go <connection index>
usage-set=Usage: !set <key><=/ ><value>
usage-columns=Usage: !columns <table name>
usage-alter=Usage: !alter -A/-D[ -p key=value]
usage-log=Usage: !log[ -p key=value]
usage-compare=Usage: !compare -D/-F -H/-I [-M t1: t2][ -p key=value]
usage-execute=Usage: !execute <-s script>[ -p key=value]
usage-register=Usage: !register HBaseCatalog as temporary_table
on-start-invalid=Connection url on start is invalid
description-engine=Engine used to execute sql
force-exit=Program has been forced to exit